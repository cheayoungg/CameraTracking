# 사람 객체 감지하고 Kalman 필터를 사용하여 추적
# 이전위치와 비교해서 오른쪽으로 이동하면 R , 왼쪽으로 이동하면 L (상대적 o)
# 중앙좌표를 기준으로 오,왼 아님(절대적 x)

import cv2
import numpy as np

# 미리 학습된 Haar Cascade Classifier 모델을 로드합니다.
body_cascade = cv2.CascadeClassifier('haarcascade_fullbody.xml')

# VideoCapture 객체를 생성하여 웹캠 영상을 캡처합니다.
#cap = cv2.VideoCapture(0)
cap = cv2.VideoCapture('vtest.avi')

# 추적 알고리즘에 사용될 이전 객체 위치를 저장하는 변수를 초기화합니다.
# 첫 번째 프레임에서는 이전 객체가 없으므로 None으로 설정합니다.
previous_box = None
direction = ""

# ret, frame = video.read()
# bbox = cv2.selectROI(frame, False)

while True:
    # 웹캠으로부터 프레임을 읽어옵니다.
    ret, frame = cap.read()

    # 화면 중앙 좌표
    center_x=frame.shape[1] //2

    # 물체 위치 계산
    # 이전 위치와 현재 위치 비교하여 방향 판단
    if previous_box is not None and current_box is not None:
        previous_center_x = (previous_box[0] + previous_box[2]) // 2
        current_center_x = (current_box[0] + current_box[2]) // 2

        if current_center_x > previous_center_x:
            direction = 'R'
        elif current_center_x < previous_center_x:
            direction = 'L'
        else:
            direction = ''

    # 라벨 출력
    if direction:
        cv2.putText(frame, direction, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)


    if ret:
        # bbox = cv2.selectROI(frame, False)
        # p1 = (int(bbox[0]), int(bbox[1]))
        # p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))
        # # 드래그 된 곳을 추적 공간으로 지정
        # cv2.rectangle(frame, p1, p2, (255, 0, 0), 2, 1)
        # current_box = (int(bbox[0], int(bbox[1], int(bbox[2]), int(bbox[3]))

        # 프레임에 객체 감지 모델을 적용하여 사람 객체를 찾습니다.
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        bodies = body_cascade.detectMultiScale(gray, 1.3, 5)

        # 감지된 객체 주위에 바운딩 박스를 그립니다.
        for (x, y, w, h) in bodies:
            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)

            # 추적 알고리즘을 적용합니다.
            current_box = (x, y, w, h)
            if previous_box is not None:
                # Kalman Filter를 사용하여 이전 객체 위치를 보정합니다.
                kalman = cv2.KalmanFilter(4, 2)
                kalman.transitionMatrix = np.array([[1, 0, 1, 0],
                                                    [0, 1, 0, 1],
                                                    [0, 0, 1, 0],
                                                    [0, 0, 0, 1]], np.float32)
                kalman.measurementMatrix = np.array([[1, 0, 0, 0],
                                                      [0, 1, 0, 0]], np.float32)
                kalman.processNoiseCov = np.array([[1, 0, 0, 0],
                                                   [0, 1, 0, 0],
                                                   [0, 0, 1, 0],
                                                   [0, 0, 0, 1]], np.float32) * 0.03
                kalman.measurementNoiseCov = np.array([[1, 0],
                                                        [0, 1]], np.float32) * 0.0001
                kalman.errorCovPost = np.array([[1, 0, 0, 0],
                                                 [0, 1, 0, 0],
                                                 [0, 0, 1, 0],
                                                 [0, 0, 0, 1]], np.float32) * 100

                # 이전 객체 위치 사용해서 kalman 필터 업데이트
                predicted_box = kalman.predict()
                kalman.correct(np.array([[np.float32(current_box[0] + current_box[2] / 2)],
                                         [np.float32(current_box[1] + current_box[3] / 2)]]))

                # 추적된 객체의 위치에 대한 정보를 출력합니다.
                cv2.putText(frame, 'Tracking', (int(predicted_box[0]), int(predicted_box[1])), cv2.FONT_HERSHEY_SIMPLEX,
                            0.6, (0, 255, 0), 2)
                cv2.rectangle(frame,
                              (int(predicted_box[0] - current_box[2] / 2), int(predicted_box[1] - current_box[3] / 2)),
                              (int(predicted_box[0] + current_box[2] / 2), int(predicted_box[1] + current_box[3] / 2)),
                              (0, 255, 0), 2)
            else:
                # 이전 객체 위치가 없는 경우, 현재 객체 위치를 이전 객체 위치로 설정합니다.
                previous_box = current_box

        # 현재 객체 위치를 이전 객체 위치로 저장합니다.
        previous_box = previous_box

        # 화면에 추적 결과를 출력합니다.
        cv2.imshow('Tracking', frame)

    # 'q' 키를 누르면 프로그램을 종료합니다.
    if cv2.waitKey(100) & 0xFF == ord('q'):
        break

# 사용한 자원을 해제합니다
cap.release()
cv2.destroyAllWindows()
